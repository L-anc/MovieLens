{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plqcgZfOalj-"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/emiletimothy/Caltech-CS155-2023/blob/main/set5/set5_prob2.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vonhL4yValkA"
      },
      "source": [
        "# Problem 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7tRON0ZialkB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShSlSvA8alkC",
        "outputId": "beaef7cc-4752-49a5-e9ed-01ead3b5e008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        User ID  Movie ID  Rating\n",
            "0             0        88     4.0\n",
            "1             0       545     3.5\n",
            "2             0         7     3.0\n",
            "3             0       401     4.0\n",
            "4             0      1230     0.5\n",
            "...         ...       ...     ...\n",
            "121496      991       681     1.0\n",
            "121497      991       736     3.5\n",
            "121498      991       162     3.0\n",
            "121499      991      1242     3.5\n",
            "121500      991       321     4.5\n",
            "\n",
            "[121501 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "movies = pd.read_csv(\"../movies.csv\")\n",
        "data = pd.read_csv(\"../data.csv\")\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0.    88.     4. ]\n",
            " [   0.   545.     3.5]\n",
            " [   0.     7.     3. ]\n",
            " ...\n",
            " [ 991.   162.     3. ]\n",
            " [ 991.  1242.     3.5]\n",
            " [ 991.   321.     4.5]]\n",
            "121501\n",
            "[[   0.    88.     4. ]\n",
            " [   0.   545.     3.5]\n",
            " [   0.    88.     4. ]\n",
            " ...\n",
            " [ 712.    57.     5. ]\n",
            " [ 727.  1492.     3.5]\n",
            " [ 864.   193.     3.5]]\n"
          ]
        }
      ],
      "source": [
        "Y = np.array(data)\n",
        "print(Y)\n",
        "print(len(Y))\n",
        "random.shuffle(Y)\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "gkB-VAH2alkD"
      },
      "outputs": [],
      "source": [
        "from numpy.random.mtrand import gamma\n",
        "def grad_U(Ui, Yij, Vj, Ai, Bj, reg, eta):\n",
        "    \"\"\"\n",
        "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
        "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
        "    and eta (the learning rate).\n",
        "\n",
        "    Returns the gradient of the regularized loss function with\n",
        "    respect to Ui multiplied by eta.\n",
        "    \"\"\"\n",
        "    sum = Vj*(Yij - (np.dot(Ui, Vj) + Ai + Bj))\n",
        "    grad = reg*Ui-sum\n",
        "    return eta*grad\n",
        "\n",
        "def grad_V(Vj, Yij, Ui, Ai, Bj, reg, eta):\n",
        "    \"\"\"\n",
        "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
        "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
        "    and eta (the learning rate).\n",
        "\n",
        "    Returns the gradient of the regularized loss function with\n",
        "    respect to Vj multiplied by eta.\n",
        "    \"\"\"\n",
        "    sum = Ui*(Yij - (np.dot(Ui, Vj) + Ai + Bj))\n",
        "    grad = reg*Vj-sum\n",
        "    return eta*grad\n",
        "\n",
        "def grad_A(Vj, Yij, Ui, Ai, Bj, eta): ############ NEW\n",
        "    \"\"\"\n",
        "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
        "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
        "    and eta (the learning rate).\n",
        "\n",
        "    Returns the gradient of the regularized loss function with\n",
        "    respect to Vj multiplied by eta.\n",
        "    \"\"\"\n",
        "    grad = -(Yij - (np.dot(Ui, Vj) + Ai + Bj))\n",
        "    return eta*grad\n",
        "\n",
        "def grad_B(Vj, Yij, Ui, Ai, Bj, eta): ############ NEW\n",
        "    \"\"\"\n",
        "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
        "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
        "    and eta (the learning rate).\n",
        "\n",
        "    Returns the gradient of the regularized loss function with\n",
        "    respect to Vj multiplied by eta.\n",
        "    \"\"\"\n",
        "    grad = -(Yij - (np.dot(Ui, Vj) + Ai + Bj))\n",
        "    return eta*grad\n",
        "\n",
        "def get_err(A, B, U, V, Y, reg=0.0):\n",
        "    \"\"\"\n",
        "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
        "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
        "    user/movie matrices U and V.\n",
        "\n",
        "    Returns the mean regularized squared-error of predictions made by\n",
        "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
        "    \"\"\"\n",
        "    sum = 0\n",
        "    for y in Y:\n",
        "      i = int(y[0])\n",
        "      j = int(y[1])\n",
        "      Yij = y[2]\n",
        "      # print(\"i: \"+str(i)+\" j: \"+str(j))\n",
        "      # print(\"len U: \"+str(len(U))+\" len V: \"+str(len(V)))\n",
        "      sum += (Yij-(np.dot(U[i], V[j]) + A[i] + B[j]))**2\n",
        "      \n",
        "    return float(sum/(2*len(Y)))\n",
        "\n",
        "\n",
        "\n",
        "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
        "    \"\"\"\n",
        "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
        "    where Y_ij is user i's rating on movie j, learns an\n",
        "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
        "    by (UV^T)_ij.\n",
        "\n",
        "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
        "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
        "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
        "    MSE after the first epoch.\n",
        "\n",
        "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
        "    of the model.\n",
        "    \"\"\"\n",
        "    U = np.random.uniform(low=-0.5, high=0.5, size=(M,K))\n",
        "    V = np.random.uniform(low=-0.5, high=0.5, size=(N,K))\n",
        "    A = np.random.uniform(low=-0.5, high=0.5, size=(M))\n",
        "    B = np.random.uniform(low=-0.5, high=0.5, size=(N))\n",
        "    e=0\n",
        "    mse_0 = get_err(A, B, U, V, Y, reg)\n",
        "    prev_mse = mse_0\n",
        "    cur_mse = mse_0\n",
        "    first_mse = 0\n",
        "    first = True\n",
        "    while e<max_epochs:\n",
        "      np.random.shuffle(Y)\n",
        "      for y in Y:\n",
        "          #we tryna minimize error of UV^T and Y\n",
        "        i = int(y[0]) #uxer\n",
        "        j = int(y[1]) #movie\n",
        "        Yij = y[2] #user's rating\n",
        "\n",
        "        #build U and V using gradient descent\n",
        "        ##### wouold we update the A and B here??\n",
        "          #update the values for a specific user's movie pref params\n",
        "        U[i] -= grad_U(U[i], Yij, V[j], A[i], B[j], reg, eta) \n",
        "          #update the values for a specific movie's relationships to users\n",
        "        V[j] -= grad_V(V[j], Yij, U[i], A[i], B[j], reg, eta)\n",
        "\n",
        "        A -= grad_A(V[j], Yij, U[i], A[i], B[j], eta) \n",
        "        B -= grad_B(V[j], Yij, U[i], A[i], B[j], eta)\n",
        "\n",
        "      #obtain the error\n",
        "      cur_mse = get_err(A, B, U, V, Y, reg)\n",
        "      if(first):\n",
        "        first_mse = mse_0-cur_mse\n",
        "        first = False\n",
        "      #stop when change in error gets too small\n",
        "      if (prev_mse-cur_mse)<=(first_mse*eps):\n",
        "        break\n",
        "\n",
        "      prev_mse = cur_mse\n",
        "      e += 1\n",
        "\n",
        "    return U, V, A, B, cur_mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_train = Y[0:109351]\n",
        "Y_test = Y[109351:121501]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "TR0VOxmAalkF",
        "outputId": "12b35432-8839-4ddd-97fe-0647f321488a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Factorizing with  992  users,  1500  movies.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
        "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
        "\n",
        "M += 1\n",
        "N += 1\n",
        "print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
        "K = 20\n",
        "\n",
        "reg = 0.0\n",
        "eta = 0.03 # learning rate\n",
        "E_in = []\n",
        "E_out = []\n",
        "\n",
        "# Use to compute Ein and Eout\n",
        "\n",
        "U,V, A,B, err = train_model(M, N, K, eta, reg, Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing error: 0.3990683537970572\n"
          ]
        }
      ],
      "source": [
        "# print(U)\n",
        "# print(V)\n",
        "# print(len(Y_test))\n",
        "# print(Y_test)\n",
        "print(f\"Testing error: {get_err(A, B, U, V, Y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfCJX9GaalkG"
      },
      "source": [
        "## 2E:\n",
        "Run the cell below to get your graphs. This might take a long time to run, but it should take less than 2 hours. I would encourage you to validate your 2C is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIkTHtTFalkH"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "train.txt not found.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(\u001b[39m'\u001b[39;49m\u001b[39mtrain.txt\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m      2\u001b[0m Y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(\u001b[39m'\u001b[39m\u001b[39mtest.txt\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m      4\u001b[0m M \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mmax\u001b[39m(Y_train[:,\u001b[39m0\u001b[39m]), \u001b[39mmax\u001b[39m(Y_test[:,\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m) \u001b[39m# users\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\maxwe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:1313\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1311\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1313\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[0;32m   1314\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[0;32m   1315\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   1316\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[0;32m   1318\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
            "File \u001b[1;32mc:\\Users\\maxwe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:955\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    953\u001b[0m     fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(fname)\n\u001b[0;32m    954\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 955\u001b[0m     fh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49m_datasource\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[0;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m         encoding \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fh, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\maxwe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
            "File \u001b[1;32mc:\\Users\\maxwe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m    531\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[0;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: train.txt not found."
          ]
        }
      ],
      "source": [
        "Y_train = np.loadtxt('train.txt').astype(int)\n",
        "Y_test = np.loadtxt('test.txt').astype(int)\n",
        "\n",
        "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
        "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
        "Ks = [10,20,30,50,100]\n",
        "\n",
        "regs = [10**-4, 10**-3, 10**-2, 10**-1, 1]\n",
        "eta = 0.03 # learning rate\n",
        "E_ins = []\n",
        "E_outs = []\n",
        "\n",
        "# Use to compute Ein and Eout\n",
        "for reg in regs:\n",
        "    E_ins_for_lambda = []\n",
        "    E_outs_for_lambda = []\n",
        "\n",
        "    for k in Ks:\n",
        "        print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\"%(M, N, k, eta, reg))\n",
        "        U,V, e_in = train_model(M, N, k, eta, reg, Y_train)\n",
        "        E_ins_for_lambda.append(e_in)\n",
        "        eout = get_err(U, V, Y_test)\n",
        "        E_outs_for_lambda.append(eout)\n",
        "\n",
        "    E_ins.append(E_ins_for_lambda)\n",
        "    E_outs.append(E_outs_for_lambda)\n",
        "\n",
        "\n",
        "# Plot values of E_in across k for each value of lambda\n",
        "for i in range(len(regs)):\n",
        "    plt.plot(Ks, E_ins[i], label='$E_{in}, \\lambda=$'+str(regs[i]))\n",
        "plt.title('$E_{in}$ vs. K')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()\n",
        "plt.savefig('2e_ein.png')\t\n",
        "plt.clf()\n",
        "\n",
        "# Plot values of E_out across k for each value of lambda\n",
        "for i in range(len(regs)):\n",
        "    plt.plot(Ks, E_outs[i], label='$E_{out}, \\lambda=$'+str(regs[i]))\n",
        "plt.title('$E_{out}$ vs. K')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()\t\n",
        "plt.savefig('2e_eout.png')\t\t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trmqdhzlalkI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "dda672a310be459319e33936d755d25cc47c873f998185e8076c531d6ecce25e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
